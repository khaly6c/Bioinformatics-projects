{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12bed5e0",
   "metadata": {},
   "source": [
    "### Project about RNA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45a6b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import relevant library and import data sets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe64bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#listing the content of directoru \"NetworkxGraph\"\n",
    "# which contains all PDB data file in pickle format\n",
    "files = os.listdir('NetworkxGraph')\n",
    "print(len(files))\n",
    "print(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da93a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing to know more about pickle data file\n",
    "filename ='NetworkxGraph/2KH9.pickle'\n",
    "#with open(filename, 'rb')\n",
    "f = open(filename, 'rb')\n",
    "graph = pickle.load(f)\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2cbf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is not analysis code\n",
    "#Testing to know more about content inside data file\n",
    "\n",
    "i=0\n",
    "for node, data in graph.nodes(data=True):\n",
    "    i=i+1\n",
    "    print('i=', i, 'node=', node, 'data=',data, '\\n\\n')\n",
    "    #print('i=', i, 'node=', node, 'data[nucleotide]=',data['nucleotide'], '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7241ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is not analysis code\n",
    "#Testing to know more about content inside data file\n",
    "# printing different information to gain more insight\n",
    "\n",
    "for file in files[0:10]:\n",
    "    filename ='NetworkxGraph/' + file\n",
    "    print(\"filename =\", filename)\n",
    "    #with open(filename, 'rb')\n",
    "    f = open(filename, 'rb')\n",
    "    graph = pickle.load(f)\n",
    "    print(graph)\n",
    "    i=0\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        i=i+1\n",
    "        #print('i=', i, 'node=', node, 'data=',data, '\\n\\n')\n",
    "        print('i=', i, 'node=', node, 'data[nucleotide]=',data['nucleotide'])\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e482b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is not analysis code\n",
    "#Testing to know more about content inside data file\n",
    "# printing different information to gain more insight\n",
    "\n",
    "Count=0\n",
    "for file in files[0:1]:\n",
    "    filename ='NetworkxGraph/' + file\n",
    "    print(\"filename =\", filename)\n",
    "    #with open(filename, 'rb')\n",
    "    f = open(filename, 'rb')\n",
    "    graph = pickle.load(f)\n",
    "    print(graph)\n",
    "    i=0\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        i=i+1\n",
    "        if data['nucleotide'] not in ['A', 'C', 'G', 'U']:\n",
    "            Count = Count +1\n",
    "            #print('i=', i, 'node=', node, 'data=',data, '\\n\\n')\n",
    "            print('i=', i, 'node=', node, 'data[nucleotide]=',data['nucleotide'])\n",
    "    print('\\n\\n')\n",
    "    \n",
    "print('Count=', Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ed0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c996b40e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Actual code starts from here\n",
    "# Now we know about data format and content inside file\n",
    "# We define label for RNA interactions and create data frame by reading files[0:1000]\n",
    "\n",
    "def FindColumnForLabel(name):\n",
    "    ans=-1\n",
    "    name_label=['B53', '0BPH', 'S55', 'S35', 'S53', 'CWW', '0BR', 'S33', 'CSW', \n",
    "            '7BPH', '1BPH', '1BR', 'CWS', '3BR', '9BPH', '4BPH', 'CSS', 'THW', \n",
    "            '2BR', '5BPH', 'TSH', 'TWH', 'THS', '6BR', 'TSW', '9BR', '7BR', '5BR', \n",
    "            'CHW', '2BPH', 'CSH', '3BPH', 'CHS', 'TWW', 'TSS', '6BPH', 'CWH', 'TWS',\n",
    "            '8BPH', 'THH', 'CHH', '8BR', '4BR', 'WAT']\n",
    "    for i in range(len(name_label)):\n",
    "        if name == name_label[i]:\n",
    "            ans =i   \n",
    "    if ans==-1:\n",
    "        print(\"ERROR:::: \", name, ' not found in the name_label ')\n",
    "    return ans\n",
    "##############################    \n",
    "Count=0\n",
    "Label= []\n",
    "NODE1=[]\n",
    "NODE2=[]\n",
    "NUCLEOTIDE=[]\n",
    "NUCLEOTIDE_STATUS =[]\n",
    "EDEGES=[]\n",
    "name_label=['B53', '0BPH', 'S55', 'S35', 'S53', 'CWW', '0BR', 'S33', 'CSW', \n",
    "            '7BPH', '1BPH', '1BR', 'CWS', '3BR', '9BPH', '4BPH', 'CSS', 'THW', \n",
    "            '2BR', '5BPH', 'TSH', 'TWH', 'THS', '6BR', 'TSW', '9BR', '7BR', '5BR', \n",
    "            'CHW', '2BPH', 'CSH', '3BPH', 'CHS', 'TWW', 'TSS', '6BPH', 'CWH', 'TWS',\n",
    "            '8BPH', 'THH', 'CHH', '8BR', '4BR', 'WAT']\n",
    "df_label = pd.DataFrame(columns=name_label)\n",
    "RowIndex=-1\n",
    "MyGlobalLabelList=[]\n",
    "\n",
    "for file in files:\n",
    "    filename ='NetworkxGraph/' + file\n",
    "    print(\"filename =\", filename)\n",
    "    #with open(filename, 'rb')\n",
    "    f = open(filename, 'rb')\n",
    "    graph = pickle.load(f)\n",
    "    print(graph)\n",
    "    i=0\n",
    "    j=0\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        i=i+1\n",
    "        #print('i=', i, 'node=', node, 'data=',data, '\\n\\n')\n",
    "        #print(data['nucleotide'], \" \", len(data['atoms']))\n",
    "        NODE1.append(node[0])\n",
    "        NODE2.append(node[1])\n",
    "        NUCLEOTIDE.append(data['nucleotide'])\n",
    "        if data['nucleotide'] not in ['A', 'C', 'G', 'U']:\n",
    "            Count = Count +1\n",
    "            NUCLEOTIDE_STATUS.append(1)        \n",
    "            #print('i=', i, 'node=', node, 'data=',data, '\\n\\n')\n",
    "            #print('i=', i, 'node=', node, 'data[nucleotide]=',data['nucleotide'])\n",
    "        else: \n",
    "            NUCLEOTIDE_STATUS.append(0) \n",
    "        \n",
    "    for node, data in graph.nodes(data=True):\n",
    "        mystring=''\n",
    "        #m=len(NODE1)\n",
    "        #print(\"m=\",m)\n",
    "        mylist=[]\n",
    "        RowIndex= RowIndex +1\n",
    "        for index in range(len(name_label)):\n",
    "                    df_label.at[RowIndex,name_label[index]] = 0\n",
    "                \n",
    "        for source, target, data in graph.edges(data=True):\n",
    "            j=j+1\n",
    "            \n",
    "            #print(\"j=\",j,source, target, data)\n",
    "            #print(\"data[label]=\", data['label'])\n",
    "        \n",
    "            #print(m)\n",
    "            if (node[0]==source[0] and node[1]==source[1] ) or (node[0]==target[0] and node[1]==target[1]):\n",
    "                #print(\"j=\",j,source, target, data)\n",
    "                #print(source[1], target[1], data['label'])\n",
    "                if data['label'] not in MyGlobalLabelList:\n",
    "                    MyGlobalLabelList.append(data['label'])\n",
    "                    \n",
    "                if data['label'] not in mylist:\n",
    "                    mylist.append(data['label'])\n",
    "                    MyGlobalLabelList.append(data['label'])\n",
    "                    mystring = mystring  + str(data['label']) +','\n",
    "                    index = FindColumnForLabel(data['label'])\n",
    "                    df_label.at[RowIndex,name_label[index]] = 1\n",
    "                    #print(mystring)\n",
    "        #print(tuple(mylist))\n",
    "        #print(mystring)\n",
    "        Label.append(mystring)\n",
    "        mylabel = data['label']\n",
    "        #if mylabel not in Label:\n",
    "        #    Label.append(data['label'])\n",
    "    print('\\n\\n')\n",
    "print(\"size=\",len(NODE1), \"\\n\", len(NODE2), \"\\n\", len(NUCLEOTIDE),  \"\\n\", len(Label) )    \n",
    "\n",
    "df1 = pd.DataFrame(NODE1, columns=[\"NodeLabel\"] ) \n",
    "df2 = pd.DataFrame(NODE2, columns=[\"NodeIndex\"] ) \n",
    "df3 = pd.DataFrame(NUCLEOTIDE, columns=[\"nucleotide\"] )\n",
    "df4 = pd.DataFrame(NUCLEOTIDE_STATUS, columns=[\"nuc_mod_stat\"] )\n",
    "df5 = pd.DataFrame(Label, columns=[\"label\"] ) \n",
    "\n",
    "df = df1.join(df2)\n",
    "df = df.join(df3)\n",
    "df = df.join(df4)\n",
    "df = df.join(df5)\n",
    "df = df.join(df_label)\n",
    "\n",
    "print('Count=', Count)\n",
    "print(Label)\n",
    "print(len(Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print Full data frame to different column\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e5c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check number of modified nodes(1) and unmodified nodes(0) in the data\n",
    "#We observe that there are more number of unmodified nodes compared to modified nodes\n",
    "# so we will make selection to have same number of unmodified nodes and modified nodes\n",
    "df['nuc_mod_stat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3810655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new data frame which has equal number of unmodified nodes and modified nodes\n",
    "NumberOfModifiedNode = df['nuc_mod_stat'].value_counts()[1]\n",
    "df_part = df[df['nuc_mod_stat'] ==  0]\n",
    "df_part['nuc_mod_stat'].value_counts()\n",
    "df_unmodified = df_part.loc[0:NumberOfModifiedNode-1, :]\n",
    "df_modified = df[df['nuc_mod_stat'] ==  1]\n",
    "print(df_unmodified['nuc_mod_stat'].value_counts() )\n",
    "print(NumberOfModifiedNode)\n",
    "print(df_modified['nuc_mod_stat'].value_counts() )\n",
    "df_merged = df_modified.append(df_unmodified, ignore_index=True)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0035d830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just a printing new label features that were created in previous step\n",
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb16b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for null values\n",
    "display( df.isnull().sum())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1f7109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training set and test set data\n",
    "\n",
    "# split X and y into training and testing sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df_merged.iloc[:,5:]\n",
    "y = df_merged.iloc[:,3]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "print(len(X))\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294b19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to plot 2x2 confusion matrix\n",
    "def plot_confusion_matrix(cnf_mat, LabelS, cmap=plt.cm.Blues): \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "    ims = ax.imshow(cnf_mat, interpolation='nearest', cmap=cmap)\n",
    "    cb = plt.colorbar(ims, ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(LabelS))\n",
    "    plt.xticks(tick_marks, LabelS, rotation=45)\n",
    "    plt.yticks(tick_marks, LabelS)\n",
    "    for i  in range(0,2):\n",
    "        for j in range(0,2):\n",
    "            plt.text(j,i,cnf_mat[i][j])\n",
    "\n",
    "#Retrive classification report and consfusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error\n",
    "def EvaluateModel(y_test, y_predict):\n",
    "    print( classification_report(y_test, y_predict) )\n",
    "    cnf_mat = confusion_matrix(y_test, y_predict, labels=[0,1])\n",
    "    print(cnf_mat)\n",
    "    plot_confusion_matrix(cnf_mat, LabelS=['NotModified(0)','Modified(1)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25970eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classical machine learning model called \"Support vector classifier\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "svr = SVC()\n",
    "param_grid = {} \n",
    "'''\n",
    "{  'C': [  0.15,], \n",
    "                'gamma': [0.00005, 0.00015],\n",
    "                'kernel': ['rbf'] }\n",
    "                '''\n",
    "svr_model = GridSearchCV(svr, param_grid = param_grid, cv = 2, verbose = True)\n",
    "best_svr = svr_model.fit(X_train, y_train)\n",
    "print('SupportVector', \"\\n\", \n",
    "                \"BestScore: \", best_svr.best_score_, '\\n',\n",
    "                 \"Best parameters: \", best_svr.best_params_ )\n",
    "\n",
    "\n",
    "#Predition on only test data\n",
    "y_predict_svr = svr_model.predict(X_test)\n",
    "\n",
    "EvaluateModel(y_test, y_predict_svr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f50248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predition on full data\n",
    "\n",
    "y_predict_full = svr_model.predict(X)\n",
    "\n",
    "EvaluateModel(y, y_predict_full)\n",
    "print(y_predict_full)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
