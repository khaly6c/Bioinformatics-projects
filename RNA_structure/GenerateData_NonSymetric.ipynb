{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12bed5e0",
   "metadata": {},
   "source": [
    "### Project about RNA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45a6b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import relevant library and import data sets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe64bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('NetworkxGraph')\n",
    "print(files)\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da93a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just open one file\n",
    "filename ='NetworkxGraph/2KH9.pickle'\n",
    "#with open(filename, 'rb')\n",
    "f = open(filename, 'rb')\n",
    "graph = pickle.load(f)\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2cbf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for node, data in graph.nodes(data=True):\n",
    "    i=i+1\n",
    "    print('i=', i, 'node=', node, 'data=',data, '\\n\\n')\n",
    "    #print('i=', i, 'node=', node, 'data[nucleotide]=',data['nucleotide'], '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7241ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files[0:10]:\n",
    "    filename ='NetworkxGraph/' + file\n",
    "    print(\"filename =\", filename)\n",
    "    #with open(filename, 'rb')\n",
    "    f = open(filename, 'rb')\n",
    "    graph = pickle.load(f)\n",
    "    print(graph)\n",
    "    i=0\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        i=i+1\n",
    "        #print('i=', i, 'node=', node, 'data=',data, '\\n\\n')\n",
    "        print('i=', i, 'node=', node, 'data[nucleotide]=',data['nucleotide'])\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e482b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a dummy testing \n",
    "Count=0\n",
    "for file in files[0:1]:\n",
    "    filename ='NetworkxGraph/' + file\n",
    "    print(\"filename =\", filename)\n",
    "    #with open(filename, 'rb')\n",
    "    f = open(filename, 'rb')\n",
    "    graph = pickle.load(f)\n",
    "    print(graph)\n",
    "    i=0\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        i=i+1\n",
    "        if data['nucleotide'] not in ['A', 'C', 'G', 'U']:\n",
    "            Count = Count +1\n",
    "            #print('i=', i, 'node=', node, 'data=',data, '\\n\\n')\n",
    "            print('i=', i, 'node=', node, 'data[nucleotide]=',data['nucleotide'])\n",
    "    print('\\n\\n')\n",
    "    \n",
    "print('Count=', Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ed0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c996b40e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def FindColumnForLabel(name):\n",
    "    ans=-1\n",
    "    name_label=['B53', '0BPH', 'S55', 'S35', 'S53', 'CWW', '0BR', 'S33', 'CSW', \n",
    "            '7BPH', '1BPH', '1BR', 'CWS', '3BR', '9BPH', '4BPH', 'CSS', 'THW', \n",
    "            '2BR', '5BPH', 'TSH', 'TWH', 'THS', '6BR', 'TSW', '9BR', '7BR', '5BR', \n",
    "            'CHW', '2BPH', 'CSH', '3BPH', 'CHS', 'TWW', 'TSS', '6BPH', 'CWH', 'TWS',\n",
    "            '8BPH', 'THH', 'CHH', '8BR', '4BR', 'WAT']\n",
    "    for i in range(len(name_label)):\n",
    "        if name == name_label[i]:\n",
    "            ans =i   \n",
    "    if ans==-1:\n",
    "        print(\"ERROR:::: \", name, ' not found in the name_label ')\n",
    "    return ans\n",
    "##############################    \n",
    "Count=0\n",
    "Label= []\n",
    "NODE1=[]\n",
    "NODE2=[]\n",
    "NUCLEOTIDE=[]\n",
    "NUCLEOTIDE_STATUS =[]\n",
    "EDEGES=[]\n",
    "name_label=['B53', '0BPH', 'S55', 'S35', 'S53', 'CWW', '0BR', 'S33', 'CSW', \n",
    "            '7BPH', '1BPH', '1BR', 'CWS', '3BR', '9BPH', '4BPH', 'CSS', 'THW', \n",
    "            '2BR', '5BPH', 'TSH', 'TWH', 'THS', '6BR', 'TSW', '9BR', '7BR', '5BR', \n",
    "            'CHW', '2BPH', 'CSH', '3BPH', 'CHS', 'TWW', 'TSS', '6BPH', 'CWH', 'TWS',\n",
    "            '8BPH', 'THH', 'CHH', '8BR', '4BR', 'WAT']\n",
    "df_label = pd.DataFrame(columns=name_label)\n",
    "RowIndex=-1\n",
    "MyGlobalLabelList=[]\n",
    "\n",
    "for file in files[95:100]:\n",
    "    filename ='NetworkxGraph/' + file\n",
    "    print(\"filename =\", filename)\n",
    "    #with open(filename, 'rb')\n",
    "    f = open(filename, 'rb')\n",
    "    graph = pickle.load(f)\n",
    "    print(graph)\n",
    "    i=0\n",
    "    j=0\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        i=i+1\n",
    "        #print('i=', i, 'node=', node, 'data=',data, '\\n\\n')\n",
    "        #print(data['nucleotide'], \" \", len(data['atoms']))\n",
    "        NODE1.append(node[0])\n",
    "        NODE2.append(node[1])\n",
    "        NUCLEOTIDE.append(data['nucleotide'])\n",
    "        if data['nucleotide'] not in ['A', 'C', 'G', 'U']:\n",
    "            Count = Count +1\n",
    "            NUCLEOTIDE_STATUS.append(1)        \n",
    "            #print('i=', i, 'node=', node, 'data=',data, '\\n\\n')\n",
    "            #print('i=', i, 'node=', node, 'data[nucleotide]=',data['nucleotide'])\n",
    "        else: \n",
    "            NUCLEOTIDE_STATUS.append(0) \n",
    "        \n",
    "    for node, data in graph.nodes(data=True):\n",
    "        mystring=''\n",
    "        #m=len(NODE1)\n",
    "        #print(\"m=\",m)\n",
    "        mylist=[]\n",
    "        RowIndex= RowIndex +1\n",
    "        for index in range(len(name_label)):\n",
    "                    df_label.at[RowIndex,name_label[index]] = 0\n",
    "                \n",
    "        for source, target, data in graph.edges(data=True):\n",
    "            j=j+1\n",
    "            \n",
    "            #print(\"j=\",j,source, target, data)\n",
    "            #print(\"data[label]=\", data['label'])\n",
    "        \n",
    "            #print(m)\n",
    "            if (node[0]==source[0] and node[1]==source[1] ) or (node[0]==target[0] and node[1]==target[1]):\n",
    "                #print(\"j=\",j,source, target, data)\n",
    "                #print(source[1], target[1], data['label'])\n",
    "                if data['label'] not in MyGlobalLabelList:\n",
    "                    MyGlobalLabelList.append(data['label'])\n",
    "                    \n",
    "                if data['label'] not in mylist:\n",
    "                    mylist.append(data['label'])\n",
    "                    MyGlobalLabelList.append(data['label'])\n",
    "                    mystring = mystring  + str(data['label']) +','\n",
    "                    index = FindColumnForLabel(data['label'])\n",
    "                    df_label.at[RowIndex,name_label[index]] = 1\n",
    "                    #print(mystring)\n",
    "        #print(tuple(mylist))\n",
    "        #print(mystring)\n",
    "        Label.append(mystring)\n",
    "        mylabel = data['label']\n",
    "        #if mylabel not in Label:\n",
    "        #    Label.append(data['label'])\n",
    "    print('\\n\\n')\n",
    "print(\"size=\",len(NODE1), \"\\n\", len(NODE2), \"\\n\", len(NUCLEOTIDE),  \"\\n\", len(Label) )    \n",
    "\n",
    "df1 = pd.DataFrame(NODE1, columns=[\"NodeLabel\"] ) \n",
    "df2 = pd.DataFrame(NODE2, columns=[\"NodeIndex\"] ) \n",
    "df3 = pd.DataFrame(NUCLEOTIDE, columns=[\"nucleotide\"] )\n",
    "df4 = pd.DataFrame(NUCLEOTIDE_STATUS, columns=[\"nuc_mod_stat\"] )\n",
    "df5 = pd.DataFrame(Label, columns=[\"label\"] ) \n",
    "\n",
    "df = df1.join(df2)\n",
    "df = df.join(df3)\n",
    "df = df.join(df4)\n",
    "df = df.join(df5)\n",
    "df = df.join(df_label)\n",
    "\n",
    "print('Count=', Count)\n",
    "print(Label)\n",
    "print(len(Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full data frame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e48231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nuc_mod_stat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2bd1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training set and test set data\n",
    "\n",
    "# split X and y into training and testing sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.iloc[:,5:]\n",
    "y = df.iloc[:,3]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(len(X))\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7bf809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to plot 2x2 confusion matrix\n",
    "def plot_confusion_matrix(cnf_mat, LabelS, cmap=plt.cm.Blues): \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "    ims = ax.imshow(cnf_mat, interpolation='nearest', cmap=cmap)\n",
    "    cb = plt.colorbar(ims, ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(LabelS))\n",
    "    plt.xticks(tick_marks, LabelS, rotation=45)\n",
    "    plt.yticks(tick_marks, LabelS)\n",
    "    for i  in range(0,2):\n",
    "        for j in range(0,2):\n",
    "            plt.text(j,i,cnf_mat[i][j])\n",
    "\n",
    "#Retrive classification report and consfusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error\n",
    "def EvaluateModel(y_test, y_predict):\n",
    "    print( classification_report(y_test, y_predict) )\n",
    "    cnf_mat = confusion_matrix(y_test, y_predict, labels=[0,1])\n",
    "    print(cnf_mat)\n",
    "    plot_confusion_matrix(cnf_mat, LabelS=['NotModified(0)','Modified(1)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a90f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classical machine learning model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "svr = SVC()\n",
    "param_grid = {  'C': [  0.15,], \n",
    "                'gamma': [0.00005, 0.00015],\n",
    "                'kernel': ['rbf'] }\n",
    "svr_model = GridSearchCV(svr, param_grid = param_grid, cv = 2, verbose = True)\n",
    "best_svr = svr_model.fit(X_train, y_train)\n",
    "print('SupportVector', \"\\n\", \n",
    "                \"BestScore: \", best_svr.best_score_, '\\n',\n",
    "                 \"Best parameters: \", best_svr.best_params_ )\n",
    "\n",
    "\n",
    "#Predition on only test data\n",
    "y_predict_svr = svr_model.predict(X_test)\n",
    "\n",
    "EvaluateModel(y_test, y_predict_svr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predition on full data\n",
    "\n",
    "y_predict_full = svr_model.predict(X)\n",
    "\n",
    "EvaluateModel(y, y_predict_full)\n",
    "print(y_predict_full)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
